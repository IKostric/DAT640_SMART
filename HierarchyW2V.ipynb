{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','type_hierarchy_features.json'),'r') as f:\n",
    "    type_hierarchy = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use value from parent for missing child types.\n",
    "For whole branches missing, will use overall average value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_child_w2v(t, hierarchy):\n",
    "    '''\n",
    "    Function for retrieving and finding centroid\n",
    "    '''\n",
    "    cl = hierarchy[t]['children']\n",
    "    w2v = np.zeros(100)\n",
    "    c=0\n",
    "    centroids = {}\n",
    "    lacking = []\n",
    "    if os.path.isfile(os.path.join('data','T_w2v',t)):\n",
    "        with open(os.path.join('data','T_w2v',t),'rb') as f:\n",
    "            fw2v = pickle.load(f)\n",
    "        c+=len(fw2v)\n",
    "        w2v += np.sum(checkw2v,axis=0)\n",
    "    for chld in cl:\n",
    "        cw2v, cc, dcent, clack = get_child_w2v(chld,hierarchy)\n",
    "        c+=cc\n",
    "        w2v += cw2v\n",
    "        centroids.update(dcent)\n",
    "        lacking.extend(clack)\n",
    "    if c!=0:\n",
    "        centroids[t] = w2v/c\n",
    "        #apply \n",
    "        for lch in lacking:\n",
    "            centroids[lch] = w2v/c\n",
    "        lacking = []\n",
    "    else:\n",
    "        lacking.append(t)\n",
    "    return w2v, c, centroids, lacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_types = type_hierarchy['Activity']['siblings']\n",
    "lacking_first_level = []\n",
    "centroids = {}\n",
    "for t in first_level_types:\n",
    "    t_w2v, t_c, t_centr, lacking = get_child_w2v(t,type_hierarchy)\n",
    "    if t_c == 0:\n",
    "        #adding to list of compeltely lacking branches\n",
    "        lacking_first_level.extend(lacking)\n",
    "    centroids.update(t_centr)\n",
    "avg_cent = np.zeros(100)\n",
    "for cntr in centroids.values():\n",
    "    avg_cent += cntr\n",
    "avg_cent = avg_cent/len(centroids)\n",
    "for lft in lacking_first_level:\n",
    "    centroids[lft] = avg_cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','t_hier_w2v_centr'),'wb') as f:\n",
    "    pickle.dump(centroids,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(set1,set2):\n",
    "    '''\n",
    "    Jaccard similarity for two sets.\n",
    "    '''\n",
    "    if len(set2) != 0:\n",
    "        return len(set1.intersection(set2))/len(set1.union(set2))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_token(mod,token):\n",
    "    '''\n",
    "    Tests if word is stopword, punctuation or if word does not exist in vocabulary.\n",
    "    '''\n",
    "    try:\n",
    "        return mod.vocab[token].is_stop or mod.vocab[token].is_punct\n",
    "    except:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_doc(doc,s_len=800000):\n",
    "    '''\n",
    "    Splits docs at the closes following blank space to the specified length.\n",
    "    '''\n",
    "    splits = [0]\n",
    "    while True:\n",
    "        s = splits[-1] + s_len\n",
    "        while True:\n",
    "            if s >= len(doc):\n",
    "                splits.append(len(doc))\n",
    "                return splits\n",
    "            if doc[s]==' ':\n",
    "                break\n",
    "            else:\n",
    "                s+=1\n",
    "        splits.append(s)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','document_TC_short.json'), 'r') as f:\n",
    "    t_docs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating NLP model for tokenizing, removing stopwords, extracting nouns etc.\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ch_unigrams(t, hierarchy):\n",
    "    '''\n",
    "    Function for retrieving and finding centroid\n",
    "    '''\n",
    "    cl = hierarchy[t]['children']\n",
    "    lengths = {}\n",
    "    if os.path.isfile(os.path.join('data','T_unigrams',t)):\n",
    "        with open(os.path.join('data','T_unigrams',t),'rb') as f:\n",
    "            t_unigrams = pickle.load(f)\n",
    "        lacking = []\n",
    "        lenghts = len(t_unigrams)\n",
    "    else:\n",
    "        t_unigrams = set()\n",
    "        if t in t_docs:\n",
    "            \n",
    "            splits = split_doc(t_docs[t]['body']) #splitting text to accomodate nlp model\n",
    "            for i in range(len(splits)-1):\n",
    "                nlp_text = nlp(t_docs[t]['body'][splits[i]:splits[i+1]].lower())\n",
    "                split_tokens=[token.text for token in nlp_text if not check_token(nlp,token.text)]\n",
    "                t_unigrams.update(split_tokens)\n",
    "            \n",
    "        lacking = []\n",
    "        \n",
    "        for chl in cl:\n",
    "            c_unigrams, c_lengths, c_lacking = write_ch_unigrams(chl,hierarchy)\n",
    "            t_unigrams.update(c_unigrams)\n",
    "            lengths.update(c_lengths)\n",
    "            lacking.extend(c_lacking)\n",
    "\n",
    "        if len(t_unigrams) == 0:\n",
    "            lacking.append(t)\n",
    "            \n",
    "        with open(os.path.join('data','T_unigrams',t),'wb') as f:\n",
    "            pickle.dump(t_unigrams,f)\n",
    "        \n",
    "    lengths[t] = len(t_unigrams)\n",
    "        \n",
    "    return t_unigrams, lengths, lacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lacking = []\n",
    "lengths = {}\n",
    "for t in first_level_types:\n",
    "    _, t_lengths, t_lacking = write_ch_unigrams(t,type_hierarchy)\n",
    "    lacking.extend(t_lacking)\n",
    "    lengths.update(t_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','lacking_J_term_types'),'wb') as f:\n",
    "    pickle.dump(lacking,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making lengths after creating files\n",
    "lengths = {}\n",
    "for t in type_hierarchy.keys():\n",
    "    with open(os.path.join('data','T_unigrams',t),'rb') as f:\n",
    "        t_unigrams = pickle.load(f)\n",
    "    lengths[t] = len(t_unigrams)\n",
    "with open(os.path.join('data','t_hier_lengths'),'wb') as f:\n",
    "    pickle.dump(lengths,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','train_query_w2v_centr'),'rb') as f:\n",
    "    train_w2v_centr = pickle.load(f)\n",
    "\n",
    "with open(os.path.join('data','test_query_w2v_centr'),'rb') as f:\n",
    "    test_w2v_centr = pickle.load(f)\n",
    "\n",
    "with open(os.path.join('data','validation_query_w2v_centr'),'rb') as f:\n",
    "    val_w2v_centr = pickle.load(f)\n",
    "    \n",
    "\n",
    "with open(os.path.join('data','train_query_unigrams'),'rb') as f:\n",
    "    train_unigrams = pickle.load(f)\n",
    "\n",
    "with open(os.path.join('data','test_query_unigrams'),'rb') as f:\n",
    "    test_unigrams = pickle.load(f)\n",
    "\n",
    "with open(os.path.join('data','validation_query_unigrams'),'rb') as f:\n",
    "    val_unigrams = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting type -Agent-\n",
      "Starting type -Mill-\n",
      "Starting type -Painting-\n",
      "Starting type -OlympicResult-\n",
      "Starting type -SportsTeamMember-\n",
      "Starting type -MilitaryUnit-\n",
      "Starting type -PublicService-\n",
      "Starting type -AnimangaCharacter-\n",
      "Starting type -SoccerTournament-\n",
      "Starting type -Disease-\n",
      "Starting type -LiteraryGenre-\n",
      "Starting type -Grape-\n",
      "Starting type -BodyOfWater-\n",
      "Starting type -RaceTrack-\n",
      "Starting type -HistoricBuilding-\n",
      "Starting type -Monument-\n",
      "Starting type -Artist-\n",
      "Starting type -HorseTrainer-\n",
      "Starting type -Canoeist-\n",
      "Starting type -GeopoliticalOrganisation-\n",
      "Starting type -MouseGene-\n",
      "Starting type -GrossDomesticProductPerCapita-\n",
      "Starting type -ElectionDiagram-\n",
      "Starting type -Quote-\n",
      "Starting type -Orphan-\n",
      "Starting type -AmericanFootballTeam-\n",
      "Starting type -StillImage-\n",
      "Starting type -GaelicGamesPlayer-\n",
      "Starting type -Novel-\n",
      "Starting type -Skater-\n",
      "Starting type -Curler-\n",
      "Starting type -GovernmentalAdministrativeRegion-\n",
      "Starting type -Garden-\n",
      "Starting type -ClassicalMusicArtist-\n",
      "Starting type -Eukaryote-\n",
      "Starting type -Professor-\n",
      "Starting type -VicePresident-\n",
      "Starting type -BaseballLeague-\n",
      "Starting type -HistoricalProvince-\n",
      "Starting type -EducationalInstitution-\n",
      "Starting type -SpaceStation-\n",
      "Starting type -Constellation-\n",
      "Starting type -Skier-\n",
      "Starting type -PoliticianSpouse-\n",
      "Starting type -UndergroundJournal-\n",
      "Starting type -PaintballLeague-\n",
      "Starting type -ClubMoss-\n",
      "Starting type -ClassicalMusicComposition-\n",
      "Starting type -HockeyClub-\n",
      "Starting type -Beach-\n",
      "Starting type -LacrosseLeague-\n",
      "Starting type -SerialKiller-\n",
      "Starting type -OlympicEvent-\n",
      "Starting type -ArtistDiscography-\n",
      "Starting type -Abbey-\n",
      "Starting type -Demographics-\n",
      "Starting type -FormulaOneRacing-\n",
      "Starting type -SportsEvent-\n",
      "Starting type -Linguist-\n",
      "Starting type -Sculptor-\n",
      "Starting type -Relationship-\n",
      "Starting type -Pope-\n",
      "Starting type -ChemicalCompound-\n",
      "Starting type -Beer-\n",
      "Starting type -PeriodOfArtisticStyle-\n",
      "Starting type -OverseasDepartment-\n",
      "Starting type -AustralianFootballTeam-\n",
      "Starting type -Dike-\n",
      "Starting type -Intercommunality-\n",
      "Starting type -NobleFamily-\n",
      "Starting type -WorldHeritageSite-\n",
      "Starting type -Comic-\n",
      "Starting type -Ski_jumper-\n",
      "Starting type -Arrondissement-\n",
      "Starting type -AmericanFootballLeague-\n",
      "Starting type -SportsTeam-\n",
      "Starting type -AustralianFootballLeague-\n",
      "Starting type -BroadcastNetwork-\n",
      "Starting type -NobelPrize-\n",
      "Starting type -Marriage-\n",
      "Starting type -HockeyTeam-\n",
      "Starting type -Murderer-\n",
      "Starting type -Decoration-\n",
      "Starting type -WrestlingEvent-\n",
      "Starting type -Municipality-\n",
      "Starting type -Bridge-\n",
      "Starting type -District-\n",
      "Starting type -Mountain-\n",
      "Starting type -RollerCoaster-\n",
      "Starting type -CyclingRace-\n",
      "Starting type -TrackList-\n",
      "Starting type -Archive-\n",
      "Starting type -Lock-\n",
      "Starting type -Cave-\n",
      "Starting type -HandballTeam-\n",
      "Starting type -Scientist-\n",
      "Starting type -Humorist-\n",
      "Starting type -Website-\n",
      "Starting type -Lymph-\n",
      "Starting type -TelevisionDirector-\n",
      "Starting type -ResearchProject-\n",
      "Starting type -Locality-\n",
      "Starting type -Animal-\n",
      "Starting type -Continent-\n",
      "Starting type -Singer-\n",
      "Starting type -BaseballSeason-\n",
      "Starting type -CricketTeam-\n",
      "Starting type -MemberResistanceMovement-\n",
      "Starting type -MilitaryAircraft-\n",
      "Starting type -Arena-\n",
      "Starting type -SoccerLeagueSeason-\n",
      "Starting type -Criminal-\n",
      "Starting type -DisneyCharacter-\n",
      "Starting type -Surname-\n",
      "Starting type -Mammal-\n",
      "Starting type -Medicine-\n",
      "Starting type -Election-\n",
      "Starting type -MobilePhone-\n",
      "Starting type -Crater-\n",
      "Starting type -BoxingLeague-\n",
      "Starting type -DistrictWaterBoard-\n",
      "Starting type -RadioControlledRacingLeague-\n",
      "Starting type -Fungus-\n",
      "Starting type -HistoricalCountry-\n",
      "Starting type -Aircraft-\n",
      "Starting type -List-\n",
      "Starting type -State-\n",
      "Starting type -FictionalCharacter-\n",
      "Starting type -Moss-\n",
      "Starting type -TennisLeague-\n",
      "Starting type -Biomolecule-\n",
      "Starting type -Station-\n",
      "Starting type -River-\n",
      "Starting type -Organisation-\n",
      "Starting type -Image-\n",
      "Starting type -ComicsCharacter-\n",
      "Starting type -Temple-\n",
      "Starting type -Cheese-\n",
      "Starting type -HorseRider-\n",
      "Starting type -Place-\n",
      "Starting type -RestArea-\n",
      "Starting type -Embryology-\n",
      "Starting type -Unknown-\n",
      "Starting type -Publisher-\n",
      "Starting type -CrossCountrySkier-\n",
      "Starting type -StormSurge-\n",
      "Starting type -FillingStation-\n",
      "Starting type -MultiVolumePublication-\n",
      "Starting type -PlayWright-\n",
      "Starting type -BoxingCategory-\n",
      "Starting type -RouteOfTransportation-\n",
      "Starting type -SportsTeamSeason-\n",
      "Starting type -FormulaOneTeam-\n",
      "Starting type -On-SiteTransportation-\n",
      "Starting type -Resume-\n",
      "Starting type -ArtificialSatellite-\n",
      "Starting type -GreenAlga-\n",
      "Starting type -SkiResort-\n",
      "Starting type -Genre-\n",
      "Starting type -ChemicalSubstance-\n",
      "Starting type -Athletics-\n",
      "Starting type -Memorial-\n",
      "Starting type -BaseballPlayer-\n",
      "Starting type -Medician-\n",
      "Starting type -RoadTunnel-\n",
      "Starting type -NaturalRegion-\n",
      "Starting type -NationalFootballLeagueSeason-\n",
      "Starting type -Zoo-\n",
      "Starting type -CultivatedVariety-\n",
      "Starting type -Castle-\n",
      "Starting type -VicePrimeMinister-\n",
      "Starting type -Instrument-\n",
      "Starting type -Mayor-\n",
      "Starting type -Photographer-\n",
      "Starting type -Species-\n",
      "Starting type -Bank-\n",
      "Starting type -GolfCourse-\n",
      "Starting type -Dam-\n",
      "Starting type -TelevisionStation-\n",
      "Starting type -CountrySeat-\n",
      "Starting type -Race-\n",
      "Starting type -Caterer-\n",
      "Starting type -PopulatedPlace-\n",
      "Starting type -Cyclist-\n",
      "Starting type -RugbyLeague-\n",
      "Starting type -AmericanFootballCoach-\n",
      "Starting type -SoccerClub-\n",
      "Starting type -Historian-\n",
      "Starting type -Asteroid-\n",
      "Starting type -Guitarist-\n",
      "Starting type -Weapon-\n",
      "Starting type -Polyhedron-\n",
      "Starting type -Lake-\n",
      "Starting type -Lieutenant-\n",
      "Starting type -Host-\n",
      "Starting type -Celebrity-\n",
      "Starting type -Mine-\n",
      "Starting type -Letter-\n",
      "Starting type -TopicalConcept-\n",
      "Starting type -AcademicSubject-\n",
      "Starting type -Noble-\n",
      "Starting type -Lighthouse-\n",
      "Starting type -MicroRegion-\n",
      "Starting type -MemberOfParliament-\n",
      "Starting type -RouteStop-\n",
      "Starting type -WineRegion-\n",
      "Starting type -SolarEclipse-\n",
      "Starting type -Forest-\n",
      "Starting type -Deity-\n",
      "Starting type -RailwayStation-\n",
      "Starting type -Poet-\n",
      "Starting type -ChristianBishop-\n",
      "Starting type -PoloLeague-\n",
      "Starting type -AutoRacingLeague-\n",
      "Starting type -HistoricPlace-\n",
      "Starting type -Depth-\n",
      "Starting type -BritishRoyalty-\n",
      "Starting type -Boxing-\n",
      "Starting type -TelevisionHost-\n",
      "Starting type -Manhua-\n",
      "Starting type -WaterTower-\n",
      "Starting type -MythologicalFigure-\n",
      "Starting type -HistoricalRegion-\n",
      "Starting type -Building-\n",
      "Starting type -Astronaut-\n",
      "Starting type -MixedMartialArtsLeague-\n",
      "Starting type -MovingImage-\n",
      "Starting type -TermOfOffice-\n",
      "Starting type -HistoricalAreaOfAuthority-\n",
      "Starting type -AdministrativeRegion-\n",
      "Starting type -HumanDevelopmentIndex-\n",
      "Starting type -Bodybuilder-\n",
      "Starting type -Single-\n",
      "Starting type -SoftballLeague-\n",
      "Starting type -Casino-\n",
      "Starting type -RaceHorse-\n",
      "Starting type -Cartoon-\n",
      "Starting type -Contest-\n",
      "Starting type -Spacecraft-\n",
      "Starting type -RadioHost-\n",
      "Starting type -MixedMartialArtsEvent-\n",
      "Starting type -VideoGame-\n",
      "Starting type -Governor-\n",
      "Starting type -TradeUnion-\n",
      "Starting type -OfficeHolder-\n",
      "Starting type -Type-\n",
      "Starting type -MilitaryStructure-\n",
      "Starting type -Document-\n",
      "Starting type -CricketLeague-\n",
      "Starting type -RugbyClub-\n",
      "Starting type -MountainRange-\n",
      "Starting type -AustralianRulesFootballPlayer-\n",
      "Starting type -BasketballPlayer-\n",
      "Starting type -Chancellor-\n",
      "Starting type -LegalCase-\n",
      "Starting type -Crustacean-\n",
      "Starting type -Broadcaster-\n",
      "Starting type -MusicDirector-\n",
      "Starting type -Cycad-\n"
     ]
    }
   ],
   "source": [
    "Q_T_features = {}\n",
    "with open(os.path.join('data','t_hier_w2v_centr'),'rb') as f:\n",
    "    t_wv = pickle.load(f)\n",
    "for t in type_hierarchy.keys():\n",
    "    if os.path.isfile(os.path.join('data','T_features',t)):\n",
    "        continue\n",
    "    print('Starting type  -{}-'.format(t))\n",
    "    with open(os.path.join('data','T_unigrams',t),'rb') as f:\n",
    "        t_unigrams = pickle.load(f)\n",
    "    Q_T_features={'train':{},'test':{},'val':{}}\n",
    "    Q_T_features['train']['SIMAGGR'] = cosine_similarity(train_w2v_centr,[t_wv[t]])\n",
    "    Q_T_features['test']['SIMAGGR'] = cosine_similarity(test_w2v_centr,[t_wv[t]])\n",
    "    Q_T_features['val']['SIMAGGR'] = cosine_similarity(val_w2v_centr,[t_wv[t]])\n",
    "    \n",
    "    Q_T_features['train']['JTERMS'] = [jaccard(q_u,t_unigrams) for q_u in train_unigrams]\n",
    "    Q_T_features['test']['JTERMS'] = [jaccard(q_u,t_unigrams) for q_u in test_unigrams]\n",
    "    Q_T_features['val']['JTERMS'] = [jaccard(q_u,t_unigrams) for q_u in val_unigrams]\n",
    "    \n",
    "    with open(os.path.join('data','T_features',t),'wb') as f:\n",
    "        pickle.dump(Q_T_features,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_Q_T_features = {}\n",
    "for t in type_hierarchy.keys():\n",
    "    with open(os.path.join('data','T_features',t),'rb') as f:\n",
    "        t_features = pickle.load(f)\n",
    "    full_Q_T_features[t] = t_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate average fatures in training set\n",
    "with open(os.path.join('data','lacking_J_term_types'), 'rb') as f:\n",
    "     lacking = pickle.load(f)\n",
    "\n",
    "avg_JTERMS = {}\n",
    "\n",
    "for ds in ['train','test','val']:\n",
    "    sum_JTERMS = np.zeros(len(full_Q_T_features[t][ds]['JTERMS']))\n",
    "    c_JTERMS = 0\n",
    "    for t in full_Q_T_features:\n",
    "        if t not in lacking:\n",
    "            sum_JTERMS += np.array(full_Q_T_features[t][ds]['JTERMS'])\n",
    "            c_JTERMS+=1\n",
    "    avg_JTERMS[ds]=sum_JTERMS/c_JTERMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_JTERMS(t,ds,features,avg_JTERMS,lack_list):\n",
    "    '''\n",
    "    Calculates average JTERMS value for siblings or returns global average\n",
    "    value if siblings lack JTERMS values.\n",
    "    '''\n",
    "    siblings = type_hierarchy[t]['siblings']\n",
    "    sum_JTERMS = np.zeros(len(features[t][ds]['JTERMS']))\n",
    "    c_JTERMS = 0\n",
    "    for t in siblings:\n",
    "        if t not in lack_list:\n",
    "            sum_JTERMS += np.array(features[t][ds]['JTERMS'])\n",
    "            c_JTERMS += 1\n",
    "    if c_JTERMS >0:\n",
    "        return list(sum_JTERMS/c_JTERMS)\n",
    "    else:\n",
    "        return list(avg_JTERMS[ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting JTERMS values for types lacking in dataset\n",
    "for ds in ['train','val','test']:\n",
    "    for t in lacking:\n",
    "        full_Q_T_features[t][ds]['JTERMS'] = set_JTERMS(t,ds,full_Q_T_features,avg_JTERMS,lacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data','Q_T_features'),'wb') as f:\n",
    "    pickle.dump(full_Q_T_features,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
