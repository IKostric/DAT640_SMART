{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import metrics as mtr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreClassifier Evaluation\n",
    "\n",
    "This was the notebook we used to pick between the parameters we wanted to evaluate. See the PreClassifierClass for final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QPC:\n",
    "    def __init__(self, conf='f', ngram_range = (1,2), min_df = 1, tsvd_cmp=0):\n",
    "        '''\n",
    "        Arguments\n",
    "            conf:         Configuration ID for saving or loading model\n",
    "            ngram_range:  Ngrams to use when tokenizing\n",
    "            min_df:       Minimum document frequency\n",
    "            tsvd_cmp:     How many components to include in truncated SVD decomposition.\n",
    "        '''\n",
    "        self.conf = conf\n",
    "        self.ngram_range = ngram_range\n",
    "        self.min_df = min_df\n",
    "        self.tsvd_cmp = tsvd_cmp\n",
    "        \n",
    "        self.classes = np.array(['resource', 'date', 'number', 'string', 'boolean'])\n",
    "        self.mlpc = None\n",
    "        \n",
    "    def _get_queries(self, filepath):\n",
    "        '''\n",
    "        Method for retrieving queries from file\n",
    "        '''\n",
    "        with open (filepath) as f:\n",
    "            query_file = json.load(f)\n",
    "        return query_file\n",
    "    \n",
    "    def _get_labels(self, data):\n",
    "        y_label = []\n",
    "        for query in data:\n",
    "            if query['question'] is not None:\n",
    "                if query['category']=='literal':\n",
    "                    y_label.append(np.where(self.classes==query['type'][0])[0][0])\n",
    "                else:\n",
    "                    y_label.append(np.where(self.classes==query['category'])[0][0])\n",
    "        return np.array(y_label).astype(int)\n",
    "    \n",
    "    def train(self, filepath):\n",
    "        '''\n",
    "        Method for training word vectorizer and neural network.\n",
    "        '''\n",
    "        query_file = self._get_queries(filepath)\n",
    "        queries = [q['question'] for q in query_file if q['question'] is not None]\n",
    "        try:\n",
    "            self.cv, self.mlpc, self.tsvd = self._load_model(self.conf)\n",
    "        except:\n",
    "            print('No saved model found. Training...')\n",
    "            self.cv = CountVectorizer(ngram_range = self.ngram_range, min_df = self.min_df)\n",
    "            train_vec = self.cv.fit_transform(queries)\n",
    "\n",
    "            #preparing labels\n",
    "            train_label = self._get_labels(query_file)\n",
    "            \n",
    "            if self.tsvd_cmp:\n",
    "                self.tsvd = TruncatedSVD(n_components=self.tsvd_cmp)\n",
    "                train_vec = self.tsvd.fit_transform(train_vec)\n",
    "        \n",
    "            self.mlpc = MLPClassifier(random_state=1, learning_rate_init=0.03, learning_rate='adaptive')\n",
    "            self.mlpc.fit(train_vec, train_label)\n",
    "\n",
    "    def _metrics(self, label, pred):\n",
    "        '''\n",
    "        Metrics for evaluating query preclassifier\n",
    "        '''\n",
    "        acc = mtr.accuracy_score(label, pred)\n",
    "        bacc = mtr.balanced_accuracy_score(label, pred)\n",
    "        f1_mac = mtr.f1_score(label, pred,average='macro')\n",
    "        f1_mic = mtr.f1_score(label, pred,average='micro')\n",
    "        print('Accuracy: {:.3}\\nBalanced Accuracy: {:.3}\\nF1 Macro: {:.3}\\nF1 Micro: {:.3}'.format(acc,bacc,f1_mac,f1_mic))\n",
    "        \n",
    "    def predict(self, filepath, metrics=False):\n",
    "        '''\n",
    "        Method for predicting category labels.\n",
    "        '''\n",
    "        if not self.mlpc:\n",
    "            print('Training not completed')\n",
    "            return None\n",
    "        query_file = self._get_queries(filepath)\n",
    "        queries = [q['question'] for q in query_file if q['question'] is not None]\n",
    "        y_labels = self._get_labels(query_file)\n",
    "        vec = self.cv.transform(queries)\n",
    "        if self.tsvd_cmp:\n",
    "            vec = self.tsvd.transform(vec)\n",
    "        pred = self.mlpc.predict(vec)\n",
    "        if metrics:\n",
    "            self._metrics(y_labels, pred)\n",
    "        return pred\n",
    "    \n",
    "    def save_model(self):\n",
    "        if self.mlpc:\n",
    "            with open('qpccv-' + self.conf + '.sav','wb') as f:\n",
    "                pickle.dump(self.cv,f)\n",
    "            with open('qpcmlpc-' + self.conf + '.sav','wb') as f:\n",
    "                pickle.dump(self.mlpc,f)\n",
    "            if self.tsvd_cmp:\n",
    "                with open('qpctsvd-' + self.conf + '.sav','wb') as f:\n",
    "                    pickle.dump(self.tsvd,f)\n",
    "        else:\n",
    "            print('Model not trained.')\n",
    "            \n",
    "    def _load_model(self, conf):\n",
    "        d = 'd' if self.tsvd_cmp else 'r'\n",
    "        tsvd = None\n",
    "        with open('qpccv-'+ self.conf + '.sav','rb') as f:\n",
    "            cv = pickle.load(f)\n",
    "        with open('qpcmlpc-' + self.conf + '.sav','rb') as f:\n",
    "            mlpc = pickle.load(f)\n",
    "        if self.tsvd_cmp:\n",
    "            with open('qpctsvd-' + self.conf + '.sav','rb') as f:\n",
    "                tsvd = pickle.load(f)\n",
    "        return [cv, mlpc, tsvd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models = \\\n",
    "[QPC(conf='tc1', min_df = 1), \\\n",
    " QPC(conf='tc2', min_df = 0.01), \\\n",
    " QPC(conf='tc3', min_df = 0.005), \\\n",
    " QPC(conf='tc4', min_df = 0.0005), \\\n",
    " QPC(conf='tc5', min_df = 1, tsvd_cmp=1000)]\n",
    "\n",
    "text = \\\n",
    "['Minimum document frequency: 1, no decomposition.', \\\n",
    " 'Minimum document frequency: 1%, no decomposition.', \\\n",
    " 'Minimum document frequency: .5%, no decomposition.', \\\n",
    " 'Minimum document frequency: .05%, no decomposition.',\\\n",
    " 'Minimum document frequency: 1, decomposition:1000 components.']\n",
    "\n",
    "for i, m in enumerate(test_models):\n",
    "    print(text[i])\n",
    "    m.train(os.path.join('Data','train_set'))\n",
    "    m.save_model()\n",
    "    print('\\n')\n",
    "    m.predict(os.path.join('Data','validation_set'), metrics=True)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}